from flask import Flask, request, jsonify, render_template, send_from_directory
from werkzeug.utils import secure_filename
import os
import base64
import requests
import time
import json
from PIL import Image, ImageDraw
from io import BytesIO
import re
import config

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = config.UPLOAD_FOLDER
app.config['RESULT_FOLDER'] = config.RESULT_FOLDER
app.config['MAX_CONTENT_LENGTH'] = config.MAX_CONTENT_LENGTH

# Create necessary directories
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(app.config['RESULT_FOLDER'], exist_ok=True)

# Note: We use direct API calls with requests instead of OpenAI client library
# to avoid version compatibility issues with the OpenAI library


def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in config.ALLOWED_EXTENSIONS


def add_composition_lines(image, line_type='rule_of_thirds', line_color=(255, 36, 66, 180), line_width=2):
    """
    åœ¨å›¾ç‰‡ä¸Šæ·»åŠ æ„å›¾çº¿
    
    Args:
        image: PIL Imageå¯¹è±¡
        line_type: æ„å›¾çº¿ç±»å‹
            - 'rule_of_thirds': ä¸‰åˆ†æ³•ï¼ˆä¹å®«æ ¼ï¼‰- é»˜è®¤
            - 'diagonal': å¯¹è§’çº¿
            - 'center': ä¸­å¿ƒçº¿
            - 'all': æ‰€æœ‰æ„å›¾çº¿
        line_color: çº¿æ¡é¢œè‰² (R, G, B, Alpha)ï¼Œé»˜è®¤ç²‰è‰²åŠé€æ˜
        line_width: çº¿æ¡å®½åº¦ï¼Œé»˜è®¤2åƒç´ 
    
    Returns:
        æ·»åŠ äº†æ„å›¾çº¿çš„PIL Imageå¯¹è±¡
    """
    # åˆ›å»ºå›¾ç‰‡å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå›¾
    img_with_lines = image.copy()
    
    # å¦‚æœå›¾ç‰‡æ˜¯RGBæ¨¡å¼ï¼Œè½¬æ¢ä¸ºRGBAä»¥æ”¯æŒé€æ˜åº¦
    if img_with_lines.mode != 'RGBA':
        img_with_lines = img_with_lines.convert('RGBA')
    
    # åˆ›å»ºç»˜å›¾å¯¹è±¡
    draw = ImageDraw.Draw(img_with_lines, 'RGBA')
    
    width, height = img_with_lines.size
    
    if line_type == 'rule_of_thirds' or line_type == 'all':
        # ä¸‰åˆ†æ³•æ„å›¾çº¿ï¼ˆä¹å®«æ ¼ï¼‰
        # å‚ç›´çº¿ï¼š1/3 å’Œ 2/3 ä½ç½®
        x1 = width / 3
        x2 = width * 2 / 3
        draw.line([(x1, 0), (x1, height)], fill=line_color, width=line_width)
        draw.line([(x2, 0), (x2, height)], fill=line_color, width=line_width)
        
        # æ°´å¹³çº¿ï¼š1/3 å’Œ 2/3 ä½ç½®
        y1 = height / 3
        y2 = height * 2 / 3
        draw.line([(0, y1), (width, y1)], fill=line_color, width=line_width)
        draw.line([(0, y2), (width, y2)], fill=line_color, width=line_width)
    
    if line_type == 'diagonal' or line_type == 'all':
        # å¯¹è§’çº¿
        draw.line([(0, 0), (width, height)], fill=line_color, width=line_width)
        draw.line([(width, 0), (0, height)], fill=line_color, width=line_width)
    
    if line_type == 'center' or line_type == 'all':
        # ä¸­å¿ƒçº¿
        center_x = width / 2
        center_y = height / 2
        draw.line([(center_x, 0), (center_x, height)], fill=line_color, width=line_width)
        draw.line([(0, center_y), (width, center_y)], fill=line_color, width=line_width)
    
    # å¦‚æœåŸå›¾æ˜¯RGBï¼Œè½¬æ¢å›RGBï¼ˆä¿å­˜ä¸ºJPEGéœ€è¦ï¼‰
    if image.mode == 'RGB':
        # åˆ›å»ºç™½è‰²èƒŒæ™¯
        background = Image.new('RGB', img_with_lines.size, (255, 255, 255))
        # å°†RGBAå›¾ç‰‡åˆæˆåˆ°RGBèƒŒæ™¯ä¸Š
        background.paste(img_with_lines, mask=img_with_lines.split()[3])  # ä½¿ç”¨alphaé€šé“ä½œä¸ºmask
        img_with_lines = background
    
    return img_with_lines


def analyze_image_scene(image_path):
    """Analyze image to understand scene, location, and environment"""
    try:
        with open(image_path, 'rb') as img_file:
            img_data = base64.b64encode(img_file.read()).decode('utf-8')
            image_url = f"data:image/jpeg;base64,{img_data}"
        
        # Comprehensive scene analysis
        prompt = """è¯·è¯¦ç»†åˆ†æè¿™å¼ ç…§ç‰‡çš„åœºæ™¯å’Œç¯å¢ƒï¼ŒåŒ…æ‹¬ï¼š
1. æ‹æ‘„åœ°ç‚¹ç±»å‹ï¼ˆå®¤å†…/æˆ·å¤–/åŸå¸‚/è‡ªç„¶/å»ºç­‘ç­‰ï¼‰
2. å…·ä½“åœºæ™¯æè¿°ï¼ˆå’–å•¡é¦†/å…¬å›­/è¡—é“/æµ·è¾¹/å±±æ™¯/åŠå…¬å®¤/å®¶ä¸­ç­‰ï¼‰
3. ç¯å¢ƒæ°›å›´ï¼ˆä¼‘é—²/æ­£å¼/æµªæ¼«/æ´»åŠ›/è‰ºæœ¯ç­‰ï¼‰
4. å…‰çº¿ç‰¹ç‚¹ï¼ˆè‡ªç„¶å…‰/äººå·¥å…‰/é€†å…‰/æŸ”å…‰ç­‰ï¼‰
5. é€‚åˆçš„æ‹æ‘„é£æ ¼å»ºè®®

è¯·ç”¨ç®€æ´çš„è¯­è¨€æè¿°ï¼Œé‡ç‚¹çªå‡ºåœºæ™¯ç‰¹å¾ã€‚"""

        # Use direct API call to avoid OpenAI client library version issues
        api_url = f"{config.AI_MODELSCOPE_BASE_URL}/chat/completions"
        headers = {
            "Authorization": f"Bearer {config.AI_MODELSCOPE_API_KEY}",
            "Content-Type": "application/json",
        }
        
        payload = {
            "model": config.VISION_MODEL,
            "messages": [{
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": image_url}},
                ],
            }],
            "stream": False,
            "max_tokens": 300,
        }
        
        response = requests.post(
            api_url,
            headers=headers,
            json=payload,
            timeout=config.API_REQUEST_TIMEOUT
        )
        response.raise_for_status()
        
        result = response.json()
        scene_info = result["choices"][0]["message"]["content"]
        print(f"Scene analysis: {scene_info}")
        return scene_info
            
    except Exception as e:
        print(f"Scene analysis error: {str(e)}")
        import traceback
        traceback.print_exc()
        return "æˆ·å¤–è‡ªç„¶åœºæ™¯"


def compress_image_for_api(image_path, max_size_kb=300):
    """Compress image to reduce API payload size - æ›´æ¿€è¿›çš„å‹ç¼©"""
    try:
        img = Image.open(image_path)
        
        # Convert RGBA to RGB if needed
        if img.mode == 'RGBA':
            img = img.convert('RGB')
        elif img.mode not in ['RGB', 'L']:
            img = img.convert('RGB')
        
        # æ›´å°çš„å°ºå¯¸ä»¥é€‚é… API é™åˆ¶
        max_dimension = 768  # ä»1024é™ä½åˆ°768
        if max(img.size) > max_dimension:
            ratio = max_dimension / max(img.size)
            new_size = tuple(int(dim * ratio) for dim in img.size)
            img = img.resize(new_size, Image.Resampling.LANCZOS)
        
        # Save to bytes with compression
        buffer = BytesIO()
        quality = 75  # ä»85é™ä½åˆ°75
        img.save(buffer, format='JPEG', quality=quality, optimize=True)
        
        # Reduce quality if still too large - æ›´æ¿€è¿›çš„å‹ç¼©
        while buffer.tell() > max_size_kb * 1024 and quality > 20:
            buffer = BytesIO()
            quality -= 10
            img.save(buffer, format='JPEG', quality=quality, optimize=True)
        
        final_size = buffer.tell() / 1024
        print(f"Compressed image: {final_size:.2f} KB (quality: {quality})")
        
        return base64.b64encode(buffer.getvalue()).decode('utf-8')
    except Exception as e:
        print(f"Image compression error: {str(e)}")
        # Fallback: read original file
        with open(image_path, 'rb') as f:
            return base64.b64encode(f.read()).decode('utf-8')


def generate_pose_variant_from_original(image_path, pose_description, scene_context, gender, index):
    """Generate pose illustration using text-to-image (çº¿æ¡å°äººå§¿åŠ¿æŒ‡å¯¼å›¾)"""
    try:
        base_url = config.IMAGE_MODELSCOPE_BASE_URL
        common_headers = {
            "Authorization": f"Bearer {config.IMAGE_MODELSCOPE_API_KEY}",
            "Content-Type": "application/json",
        }
        
        gender_text = "å¥³ç”Ÿ" if gender == "female" else "ç”·ç”Ÿ"
        
        # ç”Ÿæˆçº¿æ¡å°äººå§¿åŠ¿æŒ‡å¯¼å›¾çš„æç¤ºè¯
        # æ·»åŠ å®‰å…¨çº¦æŸï¼Œç¡®ä¿ç”Ÿæˆä¸“ä¸šã€å¥åº·ã€åˆé€‚çš„å§¿åŠ¿æŒ‡å¯¼å›¾
        illustration_prompt = f"""ç®€å•çš„é»‘ç™½çº¿æ¡å›¾ï¼Œ{gender_text}äººç‰©å§¿åŠ¿ç¤ºæ„å›¾ï¼š{pose_description}ã€‚
é£æ ¼è¦æ±‚ï¼š
- ç®€æ´çš„çº¿æ¡ç”»é£æ ¼
- é»‘ç™½è‰²è°ƒ
- æ¸…æ™°å±•ç¤ºå§¿åŠ¿åŠ¨ä½œ
- ç±»ä¼¼æ•™å­¦ç¤ºæ„å›¾
- ç™½è‰²èƒŒæ™¯
- ç«æŸ´äººæˆ–ç®€ç¬”ç”»é£æ ¼
- ä¸“ä¸šã€å¥åº·ã€ä¼˜é›…çš„å§¿åŠ¿
- é€‚åˆæ‘„å½±æ•™å­¦å’Œå§¿åŠ¿æŒ‡å¯¼
- æ— ä¸å½“å†…å®¹ï¼Œç¬¦åˆå®‰å…¨è§„èŒƒ"""
        
        print(f"ç”Ÿæˆå§¿åŠ¿æŒ‡å¯¼å›¾ {index}: {pose_description[:50]}...")
        print(f"Prompt: {illustration_prompt[:100]}...")
        
        # Prepare request payload - ä½¿ç”¨Qwen-Imageç”Ÿæˆ
        payload = {
            "model": config.IMAGE_GENERATION_MODEL,  # ä½¿ç”¨ Qwen/Qwen-Image
            "prompt": illustration_prompt,
            "n": 1,
            "size": "1024x1024"
        }
        
        print(f"Submitting image generation request {index}...")
        print(f"Using model: {config.IMAGE_GENERATION_MODEL}")
        
        # Submit async image generation task
        response = requests.post(
            f"{base_url}v1/images/generations",
            headers={**common_headers, "X-ModelScope-Async-Mode": "true"},
            data=json.dumps(payload, ensure_ascii=False).encode('utf-8'),
            timeout=config.API_REQUEST_TIMEOUT
        )
        
        # Log response for debugging
        print(f"Response status code: {response.status_code}")
        if response.status_code != 200:
            print(f"Response body: {response.text}")
            response.raise_for_status()
        
        result_data = response.json()
        print(f"API Response: {result_data}")
        
        task_id = result_data.get("task_id")
        if not task_id:
            print(f"No task_id in response: {result_data}")
            return None
        
        print(f"Task {index} submitted with ID: {task_id}")
        
        # Poll for completion
        max_attempts = config.IMAGE_GENERATION_TIMEOUT // config.IMAGE_GENERATION_CHECK_INTERVAL
        for attempt in range(max_attempts):
            time.sleep(config.IMAGE_GENERATION_CHECK_INTERVAL)
            
            print(f"Checking task {index} status (attempt {attempt + 1}/{max_attempts})...")
            
            result = requests.get(
                f"{base_url}v1/tasks/{task_id}",
                headers={**common_headers, "X-ModelScope-Task-Type": "image_generation"},
                timeout=config.API_REQUEST_TIMEOUT
            )
            result.raise_for_status()
            data = result.json()
            
            task_status = data.get("task_status", "UNKNOWN")
            print(f"Task {index} status: {task_status}")
            
            if task_status == "SUCCEED":
                output_images = data.get("output_images", [])
                if not output_images:
                    print(f"No output images in response: {data}")
                    return None
                
                image_url = output_images[0]
                print(f"Downloading generated image from: {image_url}")
                
                img_response = requests.get(image_url, timeout=config.API_REQUEST_TIMEOUT)
                img_response.raise_for_status()
                image = Image.open(BytesIO(img_response.content))
                
                # æ·»åŠ æ„å›¾çº¿ï¼ˆä¸‰åˆ†æ³•/ä¹å®«æ ¼ï¼‰
                # ä½¿ç”¨ç²‰è‰²åŠé€æ˜çº¿æ¡ï¼Œå®½åº¦2åƒç´ 
                image_with_lines = add_composition_lines(
                    image, 
                    line_type='rule_of_thirds',  # ä¸‰åˆ†æ³•æ„å›¾çº¿
                    line_color=(255, 36, 66, 180),  # ç²‰è‰²åŠé€æ˜ (#FF2442 with alpha)
                    line_width=2
                )
                
                filename = f"pose_variant_{index}_{int(time.time())}.jpg"
                filepath = os.path.join(app.config['RESULT_FOLDER'], filename)
                image_with_lines.save(filepath, quality=90)
                
                print(f"Successfully generated pose variant {index} with composition lines: {filename}")
                return filename
                
            elif task_status == "FAILED":
                error_msg = data.get("error", "Unknown error")
                print(f"Task {index} failed: {error_msg}")
                return None
            elif task_status in ["PENDING", "RUNNING"]:
                continue
            else:
                print(f"Unexpected task status: {task_status}")
                continue
        
        print(f"Task {index} timed out after {max_attempts} attempts")
        return None
        
    except requests.exceptions.HTTPError as e:
        print(f"HTTP Error for pose variant {index}: {str(e)}")
        if e.response is not None:
            print(f"Response status: {e.response.status_code}")
            print(f"Response body: {e.response.text}")
        return None
    except Exception as e:
        print(f"Pose variant generation error {index}: {str(e)}")
        import traceback
        traceback.print_exc()
        return None




@app.route('/')
def index():
    return render_template('index.html')


@app.route('/api/generate-poses', methods=['POST'])
def generate_poses():
    """Generate diverse pose variants based on AI scene analysis and gender"""
    data = request.get_json()
    
    image_filename = data.get('image_filename')
    gender = data.get('gender', 'female')
    
    if not image_filename:
        return jsonify({'error': 'è¯·å…ˆä¸Šä¼ å›¾ç‰‡'}), 400
    
    image_path = os.path.join(app.config['UPLOAD_FOLDER'], image_filename)
    if not os.path.exists(image_path):
        return jsonify({'error': 'å›¾ç‰‡ä¸å­˜åœ¨'}), 404
    
    try:
        gender_name = config.GENDER_OPTIONS.get(gender, 'å¥³ç”Ÿ')
        
        # AI analyzes the scene to understand context
        print("Analyzing scene...")
        scene_context = analyze_image_scene(image_path)
        
        # Get diverse poses based on scene analysis and gender
        print("Selecting diverse poses...")
        pose_descriptions = get_diverse_poses_for_scene(scene_context, gender)
        
        # Generate pose variants by editing original image
        pose_variants = []
        for idx, pose_desc in enumerate(pose_descriptions[:config.NUM_POSES_TO_GENERATE], 1):
            print(f"Generating pose variant {idx}/{config.NUM_POSES_TO_GENERATE}: {pose_desc['name']}")
            
            variant_filename = generate_pose_variant_from_original(
                image_path, 
                pose_desc['description'], 
                scene_context,
                gender, 
                idx
            )
            
            if variant_filename:
                pose_variants.append({
                    'name': pose_desc['name'],
                    'description': pose_desc['description'],
                    'category': pose_desc.get('category', ''),
                    'image': variant_filename
                })
            else:
                print(f"Failed to generate pose variant {idx}")
        
        result = {
            'status': 'success',
            'scene_analysis': scene_context,
            'gender': gender_name,
            'pose_variants': pose_variants
        }
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({'error': f'ç”Ÿæˆå¤±è´¥: {str(e)}'}), 500


@app.route('/api/upload', methods=['POST'])
def upload():
    """Simple upload endpoint that returns the filename"""
    if 'image' not in request.files:
        return jsonify({'error': 'æ²¡æœ‰ä¸Šä¼ å›¾ç‰‡'}), 400
    
    file = request.files['image']
    
    if file.filename == '':
        return jsonify({'error': 'æœªé€‰æ‹©æ–‡ä»¶'}), 400
    
    if not allowed_file(file.filename):
        return jsonify({'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼'}), 400
    
    try:
        filename = secure_filename(file.filename)
        timestamp = int(time.time())
        filename = f"{timestamp}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        
        return jsonify({
            'status': 'success',
            'filename': filename
        })
    except Exception as e:
        return jsonify({'error': f'ä¸Šä¼ å¤±è´¥: {str(e)}'}), 500


def get_diverse_poses_for_scene(scene_context, gender='female'):
    """Use AI to intelligently generate diverse poses based on scene analysis"""
    try:
        gender_text = "å¥³ç”Ÿ" if gender == "female" else "ç”·ç”Ÿ"
        
        # AI-powered pose generation prompt with safety constraints
        prompt = f"""æ ¹æ®ä»¥ä¸‹åœºæ™¯åˆ†æï¼Œä¸º{gender_text}æ™ºèƒ½ç”Ÿæˆ{config.NUM_POSES_TO_GENERATE}ä¸ªæ‘„å½±å§¿åŠ¿å»ºè®®ã€‚

åœºæ™¯ä¿¡æ¯ï¼š
{scene_context}

è¦æ±‚ï¼š
1. æ ¹æ®åœºæ™¯ç‰¹ç‚¹å’Œæ°›å›´ï¼Œç”Ÿæˆé€‚åˆè¯¥ç¯å¢ƒçš„å§¿åŠ¿
2. ç¡®ä¿å§¿åŠ¿å¤šæ ·åŒ–ï¼Œæ¶µç›–ä¸åŒé£æ ¼ï¼ˆç»å…¸ã€åŠ¨æ€ã€åå§¿ã€æƒ…æ„Ÿç­‰ï¼‰
3. è€ƒè™‘åœºæ™¯ä¸­çš„å¯ç”¨é“å…·å’Œç¯å¢ƒç‰¹ç‚¹
4. å§¿åŠ¿è¦è‡ªç„¶ã€å¯å®ç°ï¼Œé€‚åˆ{gender_text}
5. æä¾›è¯¦ç»†çš„å§¿åŠ¿æè¿°ï¼ŒåŒ…æ‹¬èº«ä½“ã€æ‰‹è‡‚ã€è…¿éƒ¨ã€è¡¨æƒ…ç­‰ç»†èŠ‚
6. **å®‰å…¨çº¦æŸï¼šæ‰€æœ‰å§¿åŠ¿å¿…é¡»ä¸“ä¸šã€å¥åº·ã€ä¼˜é›…ï¼Œé€‚åˆæ‘„å½±æ•™å­¦å’Œå§¿åŠ¿æŒ‡å¯¼ï¼Œæ— ä¸å½“å†…å®¹ï¼Œç¬¦åˆå®‰å…¨è§„èŒƒ**

è¯·ä»¥JSONæ ¼å¼è¿”å›{config.NUM_POSES_TO_GENERATE}ä¸ªå§¿åŠ¿ï¼Œæ¯ä¸ªå§¿åŠ¿åŒ…å«ï¼š
- name: å§¿åŠ¿åç§°ï¼ˆç®€çŸ­æœ‰å¸å¼•åŠ›ï¼‰
- description: è¯¦ç»†çš„å§¿åŠ¿æè¿°ï¼ˆå¦‚ä½•æ‘†æ”¾èº«ä½“ã€æ‰‹è‡‚ã€è¡¨æƒ…ç­‰ï¼Œå¯ä»¥è¯¦ç»†æè¿°ï¼‰
- category: å§¿åŠ¿ç±»åˆ«ï¼ˆç»å…¸/åŠ¨æ€/åå§¿/æƒ…æ„Ÿ/è‰ºæœ¯/äº’åŠ¨/æ—¶å°š/å€šé ï¼‰

æ ¼å¼ç¤ºä¾‹ï¼š
[
  {{"name": "ä¼˜é›…ä¾§èº«æœ›", "description": "45åº¦ä¾§èº«ç«™ç«‹ï¼Œå¤´éƒ¨å¾®å¾®è½¬å‘é•œå¤´ï¼Œå³æ‰‹è‡ªç„¶å‚æ”¾ï¼Œå·¦æ‰‹è½»æ‰¶è…°é—´ï¼Œå±•ç°ä¼˜é›…çš„èº«ä½“æ›²çº¿", "category": "ç»å…¸"}},
  {{"name": "è‡ªç„¶æ¼«æ­¥", "description": "è‡ªç„¶è¡Œèµ°çŠ¶æ€ï¼Œå³æ‰‹è½»æ‹åŒ…æˆ–æ’©å‘ï¼Œå·¦æ‰‹è‡ªç„¶æ‘†åŠ¨ï¼Œè¡¨æƒ…è½»æ¾æ„‰æ‚¦", "category": "åŠ¨æ€"}}
]

è¯·ç›´æ¥è¿”å›JSONæ•°ç»„ï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚"""

        # Use direct API call to avoid OpenAI client library version issues
        api_url = f"{config.AI_MODELSCOPE_BASE_URL}/chat/completions"
        headers = {
            "Authorization": f"Bearer {config.AI_MODELSCOPE_API_KEY}",
            "Content-Type": "application/json",
        }
        
        payload = {
            "model": config.VISION_MODEL,
            "messages": [{
                "role": "user",
                "content": prompt
            }],
            "stream": False,
            "max_tokens": 1000,
        }
        
        response = requests.post(
            api_url,
            headers=headers,
            json=payload,
            timeout=config.API_REQUEST_TIMEOUT
        )
        response.raise_for_status()
        
        result = response.json()
        ai_response = result["choices"][0]["message"]["content"].strip()
        print(f"AI pose suggestions: {ai_response}")
        
        # Parse JSON response
        import json
        # Extract JSON from potential markdown code blocks
        if '```json' in ai_response:
            ai_response = ai_response.split('```json')[1].split('```')[0].strip()
        elif '```' in ai_response:
            ai_response = ai_response.split('```')[1].split('```')[0].strip()
        
        poses = json.loads(ai_response)
        
        # Add gender suffix to names
        for pose in poses:
            if gender_text not in pose['name']:
                pose['name'] = f"{pose['name']} Â· {gender_text}"
        
        return poses[:config.NUM_POSES_TO_GENERATE]
        
    except Exception as e:
        print(f"AI pose generation error: {str(e)}")
        # Fallback: simple default poses
        gender_suffix = "å¥³ç”Ÿ" if gender == "female" else "ç”·ç”Ÿ"
        return [
            {'name': f'è‡ªç„¶ç«™å§¿ Â· {gender_suffix}', 'description': 'è‡ªç„¶ç«™ç«‹ï¼Œä¸€æ‰‹æ’è¢‹æˆ–å‚æ”¾ï¼Œå¾®ç¬‘çœ‹å‘é•œå¤´', 'category': 'ç»å…¸'},
            {'name': f'è½»æ¾åå§¿ Â· {gender_suffix}', 'description': 'éšæ„åä¸‹ï¼ŒåŒæ‰‹è‡ªç„¶æ”¾ç½®ï¼Œè¡¨æƒ…æ”¾æ¾', 'category': 'åå§¿'},
            {'name': f'ä¾§èº«å›æœ› Â· {gender_suffix}', 'description': 'ä¾§èº«ç«™ç«‹ï¼Œå›å¤´çœ‹å‘é•œå¤´ï¼Œå±•ç°ä¼˜é›…çº¿æ¡', 'category': 'ç»å…¸'},
            {'name': f'è‡ªç”±æ¼«æ­¥ Â· {gender_suffix}', 'description': 'è‡ªç„¶è¡Œèµ°ï¼Œæ•æ‰åŠ¨æ€ç¬é—´', 'category': 'åŠ¨æ€'},
        ][:config.NUM_POSES_TO_GENERATE]






@app.route('/uploads/<filename>')
def uploaded_file(filename):
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)


@app.route('/results/<filename>')
def result_file(filename):
    return send_from_directory(app.config['RESULT_FOLDER'], filename)


if __name__ == '__main__':
    print("\n" + "="*60)
    print("ğŸ¨ PoseMind - AI Photography Pose Recommendation System")
    print("="*60)
    print(f"\nâœ¨ Server starting on http://{config.HOST}:{config.PORT}")
    print(f"ğŸ“ Upload folder: {config.UPLOAD_FOLDER}")
    print(f"ğŸ“ Results folder: {config.RESULT_FOLDER}")
    print(f"\nğŸ¤– AI Model Configuration:")
    print(f"   Vision Model: {config.VISION_MODEL}")
    print(f"   API Base URL: {config.AI_MODELSCOPE_BASE_URL}")
    print(f"\nğŸ¨ Image Generation Model Configuration:")
    print(f"   Generation Model: {config.IMAGE_GENERATION_MODEL}")
    print(f"   API Base URL: {config.IMAGE_MODELSCOPE_BASE_URL}")
    print(f"\nğŸ’¡ Open your browser and visit: http://localhost:{config.PORT}")
    print("â¹  Press Ctrl+C to stop the server\n")
    print("="*60 + "\n")
    
    app.run(debug=config.DEBUG, host=config.HOST, port=config.PORT)

