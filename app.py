from flask import Flask, request, jsonify, render_template, send_from_directory, session
from werkzeug.utils import secure_filename
import os
import base64
import requests
import time
import json
from PIL import Image, ImageDraw
from io import BytesIO
import logging
import config

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = config.UPLOAD_FOLDER
app.config['RESULT_FOLDER'] = config.RESULT_FOLDER
app.config['MAX_CONTENT_LENGTH'] = config.MAX_CONTENT_LENGTH
app.config['SESSION_COOKIE_HTTPONLY'] = config.SESSION_COOKIE_HTTPONLY
app.config['SESSION_COOKIE_SAMESITE'] = config.SESSION_COOKIE_SAMESITE
app.config['SESSION_COOKIE_SECURE'] = config.SESSION_COOKIE_SECURE
app.secret_key = config.SECRET_KEY

# Create necessary directories
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(app.config['RESULT_FOLDER'], exist_ok=True)

# Note: We use direct API calls with requests instead of OpenAI client library
# to avoid version compatibility issues with the OpenAI library


def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in config.ALLOWED_EXTENSIONS


def add_composition_lines(image, line_type='rule_of_thirds', line_color=(255, 36, 66, 180), line_width=2):
    """
    åœ¨å›¾ç‰‡ä¸Šæ·»åŠ æ„å›¾çº¿
    
    Args:
        image: PIL Imageå¯¹è±¡
        line_type: æ„å›¾çº¿ç±»å‹
            - 'rule_of_thirds': ä¸‰åˆ†æ³•ï¼ˆä¹å®«æ ¼ï¼‰- é»˜è®¤
            - 'diagonal': å¯¹è§’çº¿
            - 'center': ä¸­å¿ƒçº¿
            - 'all': æ‰€æœ‰æ„å›¾çº¿
        line_color: çº¿æ¡é¢œè‰² (R, G, B, Alpha)ï¼Œé»˜è®¤ç²‰è‰²åŠé€æ˜
        line_width: çº¿æ¡å®½åº¦ï¼Œé»˜è®¤2åƒç´ 
    
    Returns:
        æ·»åŠ äº†æ„å›¾çº¿çš„PIL Imageå¯¹è±¡
    """
    # åˆ›å»ºå›¾ç‰‡å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå›¾
    img_with_lines = image.copy()
    
    # å¦‚æœå›¾ç‰‡æ˜¯RGBæ¨¡å¼ï¼Œè½¬æ¢ä¸ºRGBAä»¥æ”¯æŒé€æ˜åº¦
    if img_with_lines.mode != 'RGBA':
        img_with_lines = img_with_lines.convert('RGBA')
    
    # åˆ›å»ºç»˜å›¾å¯¹è±¡
    draw = ImageDraw.Draw(img_with_lines, 'RGBA')
    
    width, height = img_with_lines.size
    
    if line_type == 'rule_of_thirds' or line_type == 'all':
        # ä¸‰åˆ†æ³•æ„å›¾çº¿ï¼ˆä¹å®«æ ¼ï¼‰
        # å‚ç›´çº¿ï¼š1/3 å’Œ 2/3 ä½ç½®
        x1 = width / 3
        x2 = width * 2 / 3
        draw.line([(x1, 0), (x1, height)], fill=line_color, width=line_width)
        draw.line([(x2, 0), (x2, height)], fill=line_color, width=line_width)
        
        # æ°´å¹³çº¿ï¼š1/3 å’Œ 2/3 ä½ç½®
        y1 = height / 3
        y2 = height * 2 / 3
        draw.line([(0, y1), (width, y1)], fill=line_color, width=line_width)
        draw.line([(0, y2), (width, y2)], fill=line_color, width=line_width)
    
    if line_type == 'diagonal' or line_type == 'all':
        # å¯¹è§’çº¿
        draw.line([(0, 0), (width, height)], fill=line_color, width=line_width)
        draw.line([(width, 0), (0, height)], fill=line_color, width=line_width)
    
    if line_type == 'center' or line_type == 'all':
        # ä¸­å¿ƒçº¿
        center_x = width / 2
        center_y = height / 2
        draw.line([(center_x, 0), (center_x, height)], fill=line_color, width=line_width)
        draw.line([(0, center_y), (width, center_y)], fill=line_color, width=line_width)
    
    # å¦‚æœåŸå›¾æ˜¯RGBï¼Œè½¬æ¢å›RGBï¼ˆä¿å­˜ä¸ºJPEGéœ€è¦ï¼‰
    if image.mode == 'RGB':
        # åˆ›å»ºç™½è‰²èƒŒæ™¯
        background = Image.new('RGB', img_with_lines.size, (255, 255, 255))
        # å°†RGBAå›¾ç‰‡åˆæˆåˆ°RGBèƒŒæ™¯ä¸Š
        background.paste(img_with_lines, mask=img_with_lines.split()[3])  # ä½¿ç”¨alphaé€šé“ä½œä¸ºmask
        img_with_lines = background
    
    return img_with_lines


def analyze_image_scene(image_path):
    """Analyze image to understand scene, location, and environment"""
    try:
        img_data = compress_image_for_api(image_path)
        image_url = f"data:image/jpeg;base64,{img_data}"
        
        system_prompt = config.SCENE_ANALYSIS_SYSTEM_PROMPT
        prompt = config.SCENE_ANALYSIS_USER_PROMPT

        # Use direct API call to avoid OpenAI client library version issues
        api_url = f"{config.AI_MODELSCOPE_BASE_URL}/chat/completions"
        headers = {
            "Authorization": f"Bearer {config.AI_MODELSCOPE_API_KEY}",
            "Content-Type": "application/json",
        }
        
        payload = {
            "model": config.VISION_MODEL,
            "messages": [
                {"role": "system", "content": system_prompt},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": image_url}},
                    ],
                },
            ],
            "stream": False,
            "max_tokens": 300,
        }
        
        response = requests.post(
            api_url,
            headers=headers,
            json=payload,
            timeout=config.API_REQUEST_TIMEOUT
        )
        response.raise_for_status()
        
        result = response.json()
        scene_info = result["choices"][0]["message"]["content"]
        logging.info(f"Scene analysis: {scene_info}")
        return scene_info
            
    except Exception as e:
        logging.exception(f"Scene analysis error: {str(e)}")
        return "æˆ·å¤–è‡ªç„¶åœºæ™¯"


def compress_image_for_api(image_path, max_size_kb=300):
    """Compress image to reduce API payload size - æ›´æ¿€è¿›çš„å‹ç¼©"""
    try:
        img = Image.open(image_path)
        
        # Convert RGBA to RGB if needed
        if img.mode == 'RGBA':
            img = img.convert('RGB')
        elif img.mode not in ['RGB', 'L']:
            img = img.convert('RGB')
        
        # æ›´å°çš„å°ºå¯¸ä»¥é€‚é… API é™åˆ¶
        max_dimension = 768  # ä»1024é™ä½åˆ°768
        if max(img.size) > max_dimension:
            ratio = max_dimension / max(img.size)
            new_size = tuple(int(dim * ratio) for dim in img.size)
            img = img.resize(new_size, Image.Resampling.LANCZOS)
        
        # Save to bytes with compression
        buffer = BytesIO()
        quality = 75  # ä»85é™ä½åˆ°75
        img.save(buffer, format='JPEG', quality=quality, optimize=True)
        
        # Reduce quality if still too large - æ›´æ¿€è¿›çš„å‹ç¼©
        while buffer.tell() > max_size_kb * 1024 and quality > 20:
            buffer = BytesIO()
            quality -= 10
            img.save(buffer, format='JPEG', quality=quality, optimize=True)
        
        final_size = buffer.tell() / 1024
        logging.info(f"Compressed image: {final_size:.2f} KB (quality: {quality})")
        
        return base64.b64encode(buffer.getvalue()).decode('utf-8')
    except Exception as e:
        logging.error(f"Image compression error: {str(e)}")
        # Fallback: read original file
        with open(image_path, 'rb') as f:
            return base64.b64encode(f.read()).decode('utf-8')


def generate_pose_variant_from_original(image_path, pose_description, scene_context, gender, index):
    """Generate pose illustration using text-to-image (çº¿æ¡å°äººå§¿åŠ¿æŒ‡å¯¼å›¾)"""
    try:
        base_url = config.IMAGE_MODELSCOPE_BASE_URL
        common_headers = {
            "Authorization": f"Bearer {config.IMAGE_MODELSCOPE_API_KEY}",
            "Content-Type": "application/json",
        }
        
        gender_text = "å¥³ç”Ÿ" if gender == "female" else "ç”·ç”Ÿ"
        
        illustration_prompt = config.ILLUSTRATION_PROMPT_TEMPLATE.format(
            gender=gender_text,
            pose=pose_description
        )
        
        logging.info(f"ç”Ÿæˆå§¿åŠ¿æŒ‡å¯¼å›¾ {index}: {pose_description[:50]}...")
        logging.info(f"Prompt: {illustration_prompt[:100]}...")
        
        # Prepare request payload - ä½¿ç”¨Qwen-Imageç”Ÿæˆ
        payload = {
            "model": config.IMAGE_GENERATION_MODEL,  # ä½¿ç”¨ Qwen/Qwen-Image
            "prompt": illustration_prompt,
            "n": 1,
            "size": "1024x1024"
        }
        
        logging.info(f"Submitting image generation request {index}...")
        logging.info(f"Using model: {config.IMAGE_GENERATION_MODEL}")
        
        # Submit async image generation task
        response = requests.post(
            f"{base_url}v1/images/generations",
            headers={**common_headers, "X-ModelScope-Async-Mode": "true"},
            data=json.dumps(payload, ensure_ascii=False).encode('utf-8'),
            timeout=config.API_REQUEST_TIMEOUT
        )
        
        # Log response for debugging
        logging.info(f"Response status code: {response.status_code}")
        if response.status_code != 200:
            logging.error(f"Response body: {response.text}")
            response.raise_for_status()
        
        result_data = response.json()
        logging.info(f"API Response: {result_data}")
        
        task_id = result_data.get("task_id")
        if not task_id:
            logging.error(f"No task_id in response: {result_data}")
            return None
        
        logging.info(f"Task {index} submitted with ID: {task_id}")
        
        # Poll for completion
        max_attempts = config.IMAGE_GENERATION_TIMEOUT // config.IMAGE_GENERATION_CHECK_INTERVAL
        for attempt in range(max_attempts):
            time.sleep(config.IMAGE_GENERATION_CHECK_INTERVAL)
            
            logging.info(f"Checking task {index} status (attempt {attempt + 1}/{max_attempts})...")
            
            result = requests.get(
                f"{base_url}v1/tasks/{task_id}",
                headers={**common_headers, "X-ModelScope-Task-Type": "image_generation"},
                timeout=config.API_REQUEST_TIMEOUT
            )
            result.raise_for_status()
            data = result.json()
            
            task_status = data.get("task_status", "UNKNOWN")
            logging.info(f"Task {index} status: {task_status}")
            
            if task_status == "SUCCEED":
                output_images = data.get("output_images", [])
                if not output_images:
                    logging.error(f"No output images in response: {data}")
                    return None
                
                image_url = output_images[0]
                logging.info(f"Downloading generated image from: {image_url}")
                
                img_response = requests.get(image_url, timeout=config.API_REQUEST_TIMEOUT)
                img_response.raise_for_status()
                image = Image.open(BytesIO(img_response.content))
                
                # æ·»åŠ æ„å›¾çº¿ï¼ˆä¸‰åˆ†æ³•/ä¹å®«æ ¼ï¼‰
                # ä½¿ç”¨ç²‰è‰²åŠé€æ˜çº¿æ¡ï¼Œå®½åº¦2åƒç´ 
                image_with_lines = add_composition_lines(
                    image, 
                    line_type='rule_of_thirds',  # ä¸‰åˆ†æ³•æ„å›¾çº¿
                    line_color=(255, 36, 66, 180),  # ç²‰è‰²åŠé€æ˜ (#FF2442 with alpha)
                    line_width=2
                )
                
                filename = f"pose_variant_{index}_{int(time.time())}.jpg"
                filepath = os.path.join(app.config['RESULT_FOLDER'], filename)
                if image_with_lines.mode != 'RGB':
                    image_with_lines = image_with_lines.convert('RGB')
                image_with_lines.save(filepath, quality=90)
                
                logging.info(f"Successfully generated pose variant {index} with composition lines: {filename}")
                return filename
                
            elif task_status == "FAILED":
                error_msg = data.get("error", "Unknown error")
                logging.error(f"Task {index} failed: {error_msg}")
                return None
            elif task_status in ["PENDING", "RUNNING"]:
                continue
            else:
                logging.error(f"Unexpected task status: {task_status}")
                continue
        
        logging.error(f"Task {index} timed out after {max_attempts} attempts")
        return None
        
    except requests.exceptions.HTTPError as e:
        logging.error(f"HTTP Error for pose variant {index}: {str(e)}")
        if e.response is not None:
            logging.error(f"Response status: {e.response.status_code}")
            logging.error(f"Response body: {e.response.text}")
        return None
    except Exception as e:
        logging.exception(f"Pose variant generation error {index}: {str(e)}")
        return None




@app.route('/')
def index():
    return render_template('index.html')


@app.route('/api/plan-poses', methods=['POST'])
def plan_poses():
    data = request.get_json()
    image_filename = data.get('image_filename')
    gender = data.get('gender', 'female')

    today = time.strftime('%Y-%m-%d')
    usage_date = session.get('usage_date')
    if usage_date != today:
        session['usage_date'] = today
        session['usage_count'] = 0
    count = session.get('usage_count', 0)
    if count >= 20:
        return jsonify({'error': 'ä»Šæ—¥æ¬¡æ•°å·²ç”¨å®Œï¼ˆ20/20ï¼‰ï¼Œè¯·æ˜æ—¥å†è¯•'}), 429
    session['usage_count'] = count + 1

    if not image_filename:
        return jsonify({'error': 'è¯·å…ˆä¸Šä¼ å›¾ç‰‡'}), 400
    if not config.AI_MODELSCOPE_API_KEY or not config.IMAGE_MODELSCOPE_API_KEY:
        return jsonify({'error': 'ç¼ºå°‘APIå¯†é’¥ï¼Œè¯·é…ç½®AIä¸å›¾ç‰‡ç”ŸæˆæœåŠ¡å¯†é’¥'}), 500

    image_path = os.path.join(app.config['UPLOAD_FOLDER'], image_filename)
    if not os.path.exists(image_path):
        return jsonify({'error': 'å›¾ç‰‡ä¸å­˜åœ¨'}), 404

    try:
        gender_name = config.GENDER_OPTIONS.get(gender, 'å¥³ç”Ÿ')
        scene_context = analyze_image_scene(image_path)
        pose_descriptions = get_diverse_poses_for_scene(scene_context, gender)
        result = {
            'status': 'success',
            'scene_analysis': scene_context,
            'gender': gender_name,
            'poses': pose_descriptions
        }
        return jsonify(result)
    except Exception as e:
        return jsonify({'error': f'ç”Ÿæˆå¤±è´¥: {str(e)}'}), 500


@app.route('/api/generate-poses', methods=['POST'])
def generate_poses():
    """Generate diverse pose variants based on AI scene analysis and gender"""
    data = request.get_json()
    
    image_filename = data.get('image_filename')
    gender = data.get('gender', 'female')
    
    today = time.strftime('%Y-%m-%d')
    usage_date = session.get('usage_date')
    if usage_date != today:
        session['usage_date'] = today
        session['usage_count'] = 0
    count = session.get('usage_count', 0)
    if count >= 20:
        return jsonify({'error': 'ä»Šæ—¥æ¬¡æ•°å·²ç”¨å®Œï¼ˆ20/20ï¼‰ï¼Œè¯·æ˜æ—¥å†è¯•'}), 429
    session['usage_count'] = count + 1
    
    if not image_filename:
        return jsonify({'error': 'è¯·å…ˆä¸Šä¼ å›¾ç‰‡'}), 400
    if not config.AI_MODELSCOPE_API_KEY or not config.IMAGE_MODELSCOPE_API_KEY:
        return jsonify({'error': 'ç¼ºå°‘APIå¯†é’¥ï¼Œè¯·é…ç½®AIä¸å›¾ç‰‡ç”ŸæˆæœåŠ¡å¯†é’¥'}), 500
    
    image_path = os.path.join(app.config['UPLOAD_FOLDER'], image_filename)
    if not os.path.exists(image_path):
        return jsonify({'error': 'å›¾ç‰‡ä¸å­˜åœ¨'}), 404
    
    try:
        gender_name = config.GENDER_OPTIONS.get(gender, 'å¥³ç”Ÿ')
        
        # AI analyzes the scene to understand context
        logging.info("Analyzing scene...")
        scene_context = analyze_image_scene(image_path)
        
        # Get diverse poses based on scene analysis and gender
        logging.info("Selecting diverse poses...")
        pose_descriptions = get_diverse_poses_for_scene(scene_context, gender)
        
        # Generate pose variants by editing original image
        pose_variants = []
        for idx, pose_desc in enumerate(pose_descriptions[:config.NUM_POSES_TO_GENERATE], 1):
            logging.info(f"Generating pose variant {idx}/{config.NUM_POSES_TO_GENERATE}: {pose_desc['name']}")
            
            variant_filename = generate_pose_variant_from_original(
                image_path, 
                pose_desc['description'], 
                scene_context,
                gender, 
                idx
            )
            
            if variant_filename:
                pose_variants.append({
                    'name': pose_desc['name'],
                    'description': pose_desc['description'],
                    'category': pose_desc.get('category', ''),
                    'image': variant_filename
                })
            else:
                logging.error(f"Failed to generate pose variant {idx}")
        
        result = {
            'status': 'success',
            'scene_analysis': scene_context,
            'gender': gender_name,
            'pose_variants': pose_variants
        }
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({'error': f'ç”Ÿæˆå¤±è´¥: {str(e)}'}), 500


@app.route('/api/generate-pose-image', methods=['POST'])
def generate_pose_image():
    data = request.get_json()
    image_filename = data.get('image_filename')
    gender = data.get('gender', 'female')
    pose_description = data.get('pose_description')
    scene_context = data.get('scene_context', '')
    index = int(data.get('index', 1))

    if not image_filename or not pose_description:
        return jsonify({'error': 'ç¼ºå°‘å¿…è¦å‚æ•°'}), 400
    if not config.IMAGE_MODELSCOPE_API_KEY:
        return jsonify({'error': 'ç¼ºå°‘å›¾ç‰‡ç”ŸæˆæœåŠ¡å¯†é’¥'}), 500

    image_path = os.path.join(app.config['UPLOAD_FOLDER'], image_filename)
    if not os.path.exists(image_path):
        return jsonify({'error': 'å›¾ç‰‡ä¸å­˜åœ¨'}), 404

    try:
        filename = generate_pose_variant_from_original(
            image_path,
            pose_description,
            scene_context,
            gender,
            index
        )
        if not filename:
            return jsonify({'error': 'ç”Ÿæˆå¤±è´¥'}), 500
        return jsonify({'status': 'success', 'image': filename})
    except Exception as e:
        return jsonify({'error': f'ç”Ÿæˆå¤±è´¥: {str(e)}'}), 500

@app.route('/api/upload', methods=['POST'])
def upload():
    """Simple upload endpoint that returns the filename"""
    if 'image' not in request.files:
        return jsonify({'error': 'æ²¡æœ‰ä¸Šä¼ å›¾ç‰‡'}), 400
    
    file = request.files['image']
    
    if file.filename == '':
        return jsonify({'error': 'æœªé€‰æ‹©æ–‡ä»¶'}), 400
    
    if not allowed_file(file.filename):
        return jsonify({'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼'}), 400
    
    try:
        filename = secure_filename(file.filename)
        timestamp = int(time.time())
        filename = f"{timestamp}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        try:
            Image.open(filepath).verify()
        except Exception:
            os.remove(filepath)
            return jsonify({'error': 'æ–‡ä»¶å†…å®¹æ— æ•ˆæˆ–å·²æŸå'}), 400
        
        return jsonify({
            'status': 'success',
            'filename': filename
        })
    except Exception as e:
        return jsonify({'error': f'ä¸Šä¼ å¤±è´¥: {str(e)}'}), 500


def get_diverse_poses_for_scene(scene_context, gender='female'):
    """Use AI to intelligently generate diverse poses based on scene analysis"""
    try:
        gender_text = "å¥³ç”Ÿ" if gender == "female" else "ç”·ç”Ÿ"
        system_prompt = config.POSE_SYSTEM_PROMPT
        prompt = config.POSE_USER_PROMPT_TEMPLATE.format(
            n=config.NUM_POSES_TO_GENERATE,
            categories="|".join(config.POSE_CATEGORIES),
            scene=scene_context,
            gender=gender_text,
        )

        # Use direct API call to avoid OpenAI client library version issues
        api_url = f"{config.AI_MODELSCOPE_BASE_URL}/chat/completions"
        headers = {
            "Authorization": f"Bearer {config.AI_MODELSCOPE_API_KEY}",
            "Content-Type": "application/json",
        }
        
        payload = {
            "model": config.VISION_MODEL,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt},
            ],
            "stream": False,
            "max_tokens": 1000,
        }
        
        response = requests.post(
            api_url,
            headers=headers,
            json=payload,
            timeout=config.API_REQUEST_TIMEOUT
        )
        response.raise_for_status()
        
        result = response.json()
        ai_response = result["choices"][0]["message"]["content"].strip()
        logging.info(f"AI pose suggestions: {ai_response}")
        
        # Parse JSON response
        import json
        # Extract JSON from potential markdown code blocks
        if '```json' in ai_response:
            ai_response = ai_response.split('```json')[1].split('```')[0].strip()
        elif '```' in ai_response:
            ai_response = ai_response.split('```')[1].split('```')[0].strip()
        
        poses = json.loads(ai_response)
        
        for pose in poses:
            if gender_text not in pose['name']:
                pose['name'] = f"{pose['name']} Â· {gender_text}"
        
        return poses[:config.NUM_POSES_TO_GENERATE]
        
    except Exception as e:
        logging.error(f"AI pose generation error: {str(e)}")
        # Fallback: simple default poses
        gender_suffix = "å¥³ç”Ÿ" if gender == "female" else "ç”·ç”Ÿ"
        return [
            {'name': f'è‡ªç„¶ç«™å§¿ Â· {gender_suffix}', 'description': 'è‡ªç„¶ç«™ç«‹ï¼Œä¸€æ‰‹æ’è¢‹æˆ–å‚æ”¾ï¼Œå¾®ç¬‘çœ‹å‘é•œå¤´', 'category': 'ç»å…¸'},
            {'name': f'è½»æ¾åå§¿ Â· {gender_suffix}', 'description': 'éšæ„åä¸‹ï¼ŒåŒæ‰‹è‡ªç„¶æ”¾ç½®ï¼Œè¡¨æƒ…æ”¾æ¾', 'category': 'åå§¿'},
            {'name': f'ä¾§èº«å›æœ› Â· {gender_suffix}', 'description': 'ä¾§èº«ç«™ç«‹ï¼Œå›å¤´çœ‹å‘é•œå¤´ï¼Œå±•ç°ä¼˜é›…çº¿æ¡', 'category': 'ç»å…¸'},
            {'name': f'è‡ªç”±æ¼«æ­¥ Â· {gender_suffix}', 'description': 'è‡ªç„¶è¡Œèµ°ï¼Œæ•æ‰åŠ¨æ€ç¬é—´', 'category': 'åŠ¨æ€'},
        ][:config.NUM_POSES_TO_GENERATE]






@app.route('/uploads/<filename>')
def uploaded_file(filename):
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)


@app.route('/results/<filename>')
def result_file(filename):
    return send_from_directory(app.config['RESULT_FOLDER'], filename)


if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')
    print("\n" + "="*60)
    print("ğŸ¨ PoseMind - AI Photography Pose Recommendation System")
    print("="*60)
    print(f"\nâœ¨ Server starting on http://{config.HOST}:{config.PORT}")
    print(f"ğŸ“ Upload folder: {config.UPLOAD_FOLDER}")
    print(f"ğŸ“ Results folder: {config.RESULT_FOLDER}")
    print(f"\nğŸ¤– AI Model Configuration:")
    print(f"   Vision Model: {config.VISION_MODEL}")
    print(f"   API Base URL: {config.AI_MODELSCOPE_BASE_URL}")
    print(f"\nğŸ¨ Image Generation Model Configuration:")
    print(f"   Generation Model: {config.IMAGE_GENERATION_MODEL}")
    print(f"   API Base URL: {config.IMAGE_MODELSCOPE_BASE_URL}")
    print(f"\nğŸ’¡ Open your browser and visit: http://localhost:{config.PORT}")
    print("â¹  Press Ctrl+C to stop the server\n")
    print("="*60 + "\n")
    
    app.run(debug=config.DEBUG, host=config.HOST, port=config.PORT)

